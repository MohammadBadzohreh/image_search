# core/ai_engine.py
import streamlit as st
from transformers import AutoProcessor, SiglipModel
from PIL import Image
import torch
import config

class AIEngine:
    @staticmethod
    @st.cache_resource
    def load_model():
        print(f"ğŸ”„ Loading AI Model on {config.DEVICE}...")
        model = SiglipModel.from_pretrained(config.MODEL_NAME).to(config.DEVICE)
        processor = AutoProcessor.from_pretrained(config.MODEL_NAME)
        return model, processor

    def get_embedding(self, image=None, text=None):
        model, processor = self.load_model()
        
        inputs = None
        if image:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¹Ú©Ø³ Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±
            if isinstance(image, str): # Ø§Ú¯Ø± Ø¢Ø¯Ø±Ø³ ÙØ§ÛŒÙ„ Ø¨ÙˆØ¯
                image = Image.open(image).convert("RGB")
            inputs = processor(images=image, return_tensors="pt").to(config.DEVICE)
            
            with torch.no_grad():
                features = model.get_image_features(**inputs)

        elif text:
            # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±
            inputs = processor(text=[text], return_tensors="pt", padding="max_length", max_length=64).to(config.DEVICE)
            with torch.no_grad():
                features = model.get_text_features(**inputs)
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø¯Ø§Ø± (Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Cosine Similarity)
        features = features / features.norm(p=2, dim=-1, keepdim=True)
        return features[0].cpu().numpy()