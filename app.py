import streamlit as st
import os
import glob
from PIL import Image
import torch
from tqdm import tqdm
import config
# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ú©Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ø³Ø§Ø®ØªÛŒÙ…
from core.ai_engine import AIEngine
from core.db_manager import DBManager

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ ---
st.set_page_config(
    page_title="Neural Search Dashboard", 
    page_icon="ğŸ§ ", 
    layout="wide"
)

st.title("ğŸ§  Neural Search Dashboard")
st.markdown("### Manage your embeddings & Bulk Indexing")

# --- Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ ---
try:
    ai = AIEngine()
    db = DBManager()
except Exception as e:
    st.error(f"âŒ System Error: {e}")
    st.stop()

# --- SIDEBAR: ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
with st.sidebar:
    st.header("âš™ï¸ Batch Config")
    
    # 1. Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ø³Ø±Øª (Ù‚Ø§Ø¨Ù„ÛŒØª Ø¬Ø¯ÛŒØ¯)
    model_options = list(config.MODELS_CONFIG.keys())
    selected_model = st.selectbox(
        "Select Target Model:", 
        model_options, 
        index=2 # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±ÙˆÛŒ Jina v2
    )
    
    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
    target_info = config.MODELS_CONFIG[selected_model]
    st.info(f"Target Collection:\n`{target_info['collection_name']}`\nDimension: `{target_info['dimension']}`")
    
    st.divider()
    
    # 2. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ú† (Ø³Ø±Ø¹Øª)
    batch_size = st.slider("Batch Size (Speed vs VRAM)", 16, 128, 64)
    
    # 3. Ú©Ù¾Ø´Ù† (Ù‡Ø´Ø¯Ø§Ø± Ø³Ø±Ø¹Øª)
    enable_caption = st.checkbox("Generate Captions (âš ï¸ Very Slow)", value=False, help="Turning this on will make indexing 50x slower!")

# --- MAIN AREA: Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ---

# ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª
default_path = config.IMAGE_STORAGE_PATH
dataset_path = st.text_input("ğŸ“ Dataset Path (Folder containing images):", value=default_path)

# Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ú©Ø§Ù„Ú©Ø´Ù†
if st.button("ğŸ“Š Check Collection Status"):
    try:
        col_name = target_info['collection_name']
        if db.client.has_collection(col_name):
            # Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§
            res = db.client.query(collection_name=col_name, output_fields=["count(*)"])
            count = res[0]["count(*)"]
            st.success(f"âœ… Collection `{col_name}` exists with **{count}** records.")
        else:
            st.warning(f"âš ï¸ Collection `{col_name}` does not exist yet (Will be created on insert).")
    except Exception as e:
        st.error(f"Connection Error: {e}")

st.divider()

# Ø¯Ú©Ù…Ù‡ Ø´Ø±ÙˆØ¹ Ø¹Ù…Ù„ÛŒØ§Øª Ø³Ù†Ú¯ÛŒÙ†
if st.button("ğŸš€ Start Batch Indexing", type="primary"):
    
    # 1. Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ÛŒØ±
    if not os.path.exists(dataset_path):
        st.error(f"âŒ Path `{dataset_path}` not found!")
        st.stop()

    # 2. Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Ø¹Ú©Ø³â€ŒÙ‡Ø§
    st.write("ğŸ“‚ Scanning for images...")
    image_files = []
    # Ø¬Ø³ØªØ¬ÙˆÛŒ ØªÙ…Ø§Ù… ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒØ¬
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG']:
        image_files.extend(glob.glob(os.path.join(dataset_path, "**", ext), recursive=True))
    
    if not image_files:
        st.warning("No images found in the specified folder.")
        st.stop()
        
    st.info(f"found **{len(image_files)}** images. Starting indexing process with **{selected_model}**...")

    # 3. Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ú©Ø§Ù„Ú©Ø´Ù† (Ø³Ø§Ø®ØªÙ† Ø¢Ù† Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯Ù†)
    db.ensure_collection(selected_model)

    # 4. Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø±)
    with st.spinner(f"Loading {selected_model} model..."):
        # ØªØ§Ø¨Ø¹ load_embedding_model Ø±Ø§ Ø§Ø² Ú©Ù„Ø§Ø³ AI Engine ØµØ¯Ø§ Ù…ÛŒâ€ŒØ²Ù†ÛŒÙ…
        # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø®Ø±ÙˆØ¬ÛŒ Ø³Ù‡ ØªØ§ÛŒÛŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯: (model, processor, model_type)
        model_data = ai.load_embedding_model(selected_model)

    # 5. Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ (Batch Loop)
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_files = len(image_files)
    processed_count = 0
    
    # ØªÙ‚Ø³ÛŒÙ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© (Batch)
    for i in range(0, total_files, batch_size):
        batch_paths = image_files[i : i + batch_size]
        
        # Ø§Ù„Ù) Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡
        # Ù†Ú©ØªÙ‡: Ù…Ø§ ØªØ§Ø¨Ø¹ get_embedding Ø±Ø§ Ø·ÙˆØ±ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø¨ÙˆØ¯ÛŒÙ… Ú©Ù‡ ØªÚ©ÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ø±Ø¯.
        # Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ± Ø¯Ø± BatchØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ… ÛŒØ§ 
        # Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ú©Ø¯ ØªÙ…ÛŒØ² Ø¨Ù…Ø§Ù†Ø¯ØŒ ÛŒÚ© ØªØ§Ø¨Ø¹ get_batch_embedding Ø¨Ù‡ AI Engine Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.
        # Ø§Ù…Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ ØªÚ© ØªÚ© Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú©Ø¯ AI Engine Ø±Ø§ Ø§Ø±ØªÙ‚Ø§ Ø¯Ù‡ÛŒØ¯)
        
        vectors = []
        valid_paths_in_batch = []
        captions = []

        for path in batch_paths:
            try:
                # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø±
                vec = ai.get_embedding(model_key=selected_model, image=path)
                
                # ØªÙˆÙ„ÛŒØ¯ Ú©Ù¾Ø´Ù† (Ø§Ú¯Ø± ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯)
                cap = ""
                if enable_caption:
                    cap = ai.generate_caption(path)
                
                vectors.append(vec)
                valid_paths_in_batch.append(path)
                captions.append(cap)
                
            except Exception as e:
                print(f"Error processing {path}: {e}")
                continue
        
        # Ø¨) Ø§ÛŒÙ†Ø³Ø±Øª Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø± Milvus
        if vectors:
            try:
                # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ù…Øª Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Milvus
                data_to_insert = []
                for idx, v in enumerate(vectors):
                    data_to_insert.append({
                        "vector": v,
                        "path": valid_paths_in_batch[idx],
                        "caption": captions[idx]
                    })
                
                # Ø¯Ø±Ø¬ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                col_name = target_info['collection_name']
                db.client.insert(col_name, data_to_insert)
                
                processed_count += len(data_to_insert)
            except Exception as e:
                st.error(f"DB Insert Error: {e}")

        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
        progress = min((i + batch_size) / total_files, 1.0)
        progress_bar.progress(progress)
        status_text.text(f"ğŸš€ Indexed {processed_count} / {total_files} images...")

    st.balloons()
    st.success(f"ğŸ‰ Batch Indexing Completed! Successfully indexed {processed_count} images into `{target_info['collection_name']}`.")