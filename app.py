# # app.py
# import streamlit as st
# import os
# import glob
# from PIL import Image
# import torch
# import config
# from core.ai_engine import AIEngine
# from core.db_manager import DBManager

# st.set_page_config(page_title="Neural Search Dashboard", page_icon="ğŸ§ ", layout="wide")
# st.title("ğŸ§  Neural Search Dashboard")

# try:
#     ai = AIEngine()
#     db = DBManager()
# except Exception as e:
#     st.error(f"âŒ System Error: {e}")
#     st.stop()

# # --- SIDEBAR ---
# with st.sidebar:
#     st.header("âš™ï¸ Batch Config")
    
#     # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø­Ø§Ù„Ø§ Ø´Ø§Ù…Ù„ Llama-Nemo Ù‡Ù… Ù‡Ø³Øª
#     model_options = list(config.MODELS_CONFIG.keys())
#     # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ (Ø§Ø­ØªÙ…Ø§Ù„Ø§ Nemo)
#     selected_model = st.selectbox("Select Target Model:", model_options, index=len(model_options)-1)
    
#     target_info = config.MODELS_CONFIG[selected_model]
#     st.info(f"Target Collection:\n`{target_info['collection_name']}`\nDim: `{target_info['dimension']}`")
    
#     st.divider()
#     # Ù…Ø¯Ù„ Nemo Ø³Ù†Ú¯ÛŒÙ† Ø§Ø³ØªØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø¨Ú† Ø³Ø§ÛŒØ² Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø§Ø´Ø¯
#     batch_size = st.slider("Batch Size", 4, 128, 32)
#     enable_caption = st.checkbox("Generate Captions (Slow)", value=False)

# # --- MAIN ---
# default_path = config.IMAGE_STORAGE_PATH
# dataset_path = st.text_input("ğŸ“ Dataset Path:", value=default_path)

# if st.button("ğŸ“Š Check Status"):
#     try:
#         col_name = target_info['collection_name']
#         if db.client.has_collection(col_name):
#             count = db.client.query(col_name, output_fields=["count(*)"])[0]["count(*)"]
#             st.success(f"âœ… `{col_name}` has **{count}** records.")
#         else:
#             st.warning(f"âš ï¸ `{col_name}` does not exist yet.")
#     except Exception as e:
#         st.error(f"Error: {e}")

# st.divider()

# if st.button("ğŸš€ Start Batch Indexing", type="primary"):
#     if not os.path.exists(dataset_path):
#         st.error("Path not found!")
#         st.stop()

#     st.write("ğŸ“‚ Scanning images...")
#     image_files = []
#     for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG']:
#         image_files.extend(glob.glob(os.path.join(dataset_path, "**", ext), recursive=True))
    
#     if not image_files:
#         st.warning("No images found.")
#         st.stop()
        
#     st.info(f"Found **{len(image_files)}** images. Indexing with **{selected_model}**...")
#     db.ensure_collection(selected_model)

#     with st.spinner(f"Loading {selected_model}..."):
#         # Ù„ÙˆØ¯ Ù…Ø¯Ù„
#         _ = ai.load_embedding_model(selected_model)

#     progress_bar = st.progress(0)
#     status_text = st.empty()
#     total_files = len(image_files)
#     processed_count = 0
    
#     for i in range(0, total_files, batch_size):
#         batch_paths = image_files[i : i + batch_size]
#         vectors = []
#         valid_paths = []
#         captions = []

#         for path in batch_paths:
#             try:
#                 # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ (Ø¨Ø±Ø§ÛŒ Nemo Ø¹Ú©Ø³ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
#                 vec = ai.get_embedding(model_key=selected_model, image=path)
                
#                 cap = ""
#                 if enable_caption:
#                     cap = ai.generate_caption(path)
                
#                 if vec is not None:
#                     vectors.append(vec)
#                     valid_paths.append(path)
#                     captions.append(cap)
#             except Exception as e:
#                 # print(f"Error: {e}")
#                 continue
        
#         if vectors:
#             data = []
#             for idx, v in enumerate(vectors):
#                 data.append({"vector": v, "path": valid_paths[idx], "caption": captions[idx]})
            
#             try:
#                 db.client.insert(target_info['collection_name'], data)
#                 processed_count += len(data)
#             except Exception as e:
#                 st.error(f"DB Error: {e}")

#         progress = min((i + batch_size) / total_files, 1.0)
#         progress_bar.progress(progress)
#         status_text.text(f"ğŸš€ Indexed {processed_count} / {total_files}...")

#     st.balloons()
#     st.success("Done!")


# app.py
import streamlit as st
import os
import glob
from PIL import Image
import torch
import config
from core.ai_engine import AIEngine
from core.db_manager import DBManager

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡ ---
st.set_page_config(page_title="Neural Search Dashboard", page_icon="ğŸ§ ", layout="wide")
st.title("ğŸ§  Neural Search Dashboard")

# --- Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…ÙˆØªÙˆØ±Ù‡Ø§ ---
try:
    ai = AIEngine()
    db = DBManager()
except Exception as e:
    st.error(f"âŒ System Error: {e}")
    st.stop()

# --- SIDEBAR: ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
with st.sidebar:
    st.header("âš™ï¸ Batch Config")
    
    # 1. Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
    model_options = list(config.MODELS_CONFIG.keys())
    # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¯Ù„ (Llama-Nemo)
    selected_model = st.selectbox("Select Target Model:", model_options, index=len(model_options)-1)
    
    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„
    target_info = config.MODELS_CONFIG[selected_model]
    st.info(f"Target Collection:\n`{target_info['collection_name']}`\nDim: `{target_info['dimension']}`")
    
    st.divider()
    
    # 2. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ú† (Batch Size)
    # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ù…Ø«Ù„ NemoØŒ Ø¹Ø¯Ø¯ Ú©Ù…ØªØ± (Ù…Ø«Ù„Ø§Ù‹ 8 ÛŒØ§ 16) Ø¨Ù‡ØªØ± Ø§Ø³Øª
    batch_size = st.slider("Batch Size", 4, 128, 16)
    
    # 3. ØªÙˆÙ„ÛŒØ¯ Ú©Ù¾Ø´Ù† (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    enable_caption = st.checkbox("Generate Captions (Optional)", value=False)

# --- MAIN AREA ---
default_path = config.IMAGE_STORAGE_PATH
dataset_path = st.text_input("ğŸ“ Dataset Path:", value=default_path)

# Ø¯Ú©Ù…Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³
if st.button("ğŸ“Š Check Status"):
    try:
        col_name = target_info['collection_name']
        if db.client.has_collection(col_name):
            res = db.client.query(collection_name=col_name, output_fields=["count(*)"])
            count = res[0]["count(*)"]
            st.success(f"âœ… Collection `{col_name}` exists with **{count}** records.")
        else:
            st.warning(f"âš ï¸ Collection `{col_name}` does not exist yet. It will be created automatically.")
    except Exception as e:
        st.error(f"Error checking DB: {e}")

st.divider()

# --- Ø¯Ú©Ù…Ù‡ Ø´Ø±ÙˆØ¹ Ø¹Ù…Ù„ÛŒØ§Øª ---
if st.button("ğŸš€ Start Batch Indexing", type="primary"):
    # 1. Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    if not os.path.exists(dataset_path):
        st.error(f"âŒ Path `{dataset_path}` not found!")
        st.stop()

    st.write("ğŸ“‚ Scanning for images...")
    image_files = []
    # Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG']:
        image_files.extend(glob.glob(os.path.join(dataset_path, "**", ext), recursive=True))
    
    if not image_files:
        st.warning("No images found in the specified folder.")
        st.stop()
        
    st.info(f"Found **{len(image_files)}** images. Starting indexing with **{selected_model}**...")
    
    # 2. Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    db.ensure_collection(selected_model)

    # 3. Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ (Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯)
    with st.spinner(f"Loading {selected_model}... (Please wait)"):
        try:
            ai.load_embedding_model(selected_model)
        except Exception as e:
            st.error(f"âŒ Failed to load model: {e}")
            st.stop()

    # 4. Ø´Ø±ÙˆØ¹ Ø­Ù„Ù‚Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´
    progress_bar = st.progress(0)
    status_text = st.empty()
    error_container = st.empty()
    
    total_files = len(image_files)
    processed_count = 0
    error_count = 0
    
    # Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ (Batch Loop)
    for i in range(0, total_files, batch_size):
        batch_paths = image_files[i : i + batch_size]
        
        vectors = []
        valid_paths = []
        captions = []

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ø¹Ú©Ø³ Ø¯Ø± Ø¨Ú†
        for path in batch_paths:
            try:
                # Ø§Ù„Ù) ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø± (Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø®ÙˆØ¯Ø´ Ù„Ø§Ø¬ÛŒÚ© Nemo/CLIP Ø±Ø§ Ù‡Ù†Ø¯Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
                vec = ai.get_embedding(model_key=selected_model, image=path)
                
                # Ø¨) ØªÙˆÙ„ÛŒØ¯ Ú©Ù¾Ø´Ù† (Ø§Ú¯Ø± ØªÛŒÚ© Ø²Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯)
                cap = ""
                if enable_caption:
                    cap = ai.generate_caption(path)
                
                if vec is not None:
                    vectors.append(vec)
                    valid_paths.append(path)
                    captions.append(cap)
            
            except Exception as e:
                # Ù†Ù…Ø§ÛŒØ´ Ø®Ø·Ø§ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ (ØªØ±Ù…ÛŒÙ†Ø§Ù„) Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
                print(f"âŒ Error processing {path}: {e}")
                error_count += 1
                if error_count <= 5: # ÙÙ‚Ø· Ûµ Ø§Ø±ÙˆØ± Ø§ÙˆÙ„ Ø±Ø§ Ø¯Ø± ØµÙØ­Ù‡ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡ Ú©Ù‡ Ø´Ù„ÙˆØº Ù†Ø´ÙˆØ¯
                    error_container.warning(f"Skipped {os.path.basename(path)}: {e}")
                continue
        
        # Ø¬) Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (ÙÙ‚Ø· Ø§Ú¯Ø± Ø¨Ø±Ø¯Ø§Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)
        if vectors:
            # Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Milvus
            data_to_insert = []
            for idx, v in enumerate(vectors):
                data_to_insert.append({
                    "vector": v,
                    "path": valid_paths[idx],
                    "caption": captions[idx]
                })
            
            try:
                # Ø§ÛŒÙ†Ø³Ø±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
                db.client.insert(target_info['collection_name'], data_to_insert)
                processed_count += len(data_to_insert)
            except Exception as e:
                st.error(f"âŒ DB Insert Error: {e}")
                # Ø§Ú¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‚Ø·Ø¹ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø¯Ù† Ø¨ÛŒâ€ŒÙØ§ÛŒØ¯Ù‡ Ø§Ø³Øª
                st.stop()

        # Ø¯) Ø¢Ù¾Ø¯ÛŒØª Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª
        progress = min((i + batch_size) / total_files, 1.0)
        progress_bar.progress(progress)
        status_text.text(f"ğŸš€ Indexed {processed_count} / {total_files} images... (Errors: {error_count})")

    st.balloons()
    st.success(f"ğŸ‰ Done! Successfully indexed **{processed_count}** images.")
    if error_count > 0:
        st.warning(f"âš ï¸ Skipped {error_count} images due to errors. Check terminal logs for details.")